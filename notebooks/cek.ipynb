{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2dd9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\victus\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (2.0.32)\n",
      "Requirement already satisfied: tqdm in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.14.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\victus\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\victus\\appdata\\roaming\\python\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\victus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install optuna xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7ef508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import hamming_loss, jaccard_score\n",
    "import logging\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144ca50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewPreprocessor:\n",
    "    def __init__(self):\n",
    "        # Indonesian slang dictionary for normalization\n",
    "        self.slang_dict = {\n",
    "            # Quality terms\n",
    "            'bgus': 'bagus',\n",
    "            'bgs': 'bagus',\n",
    "            'mantap': 'bagus',\n",
    "            'mantul': 'bagus',\n",
    "            'oke': 'bagus',\n",
    "            'ok': 'bagus',\n",
    "            'jelek': 'buruk',\n",
    "            'ancur': 'buruk',\n",
    "            'rusak': 'buruk',\n",
    "            'parah': 'buruk',\n",
    "            \n",
    "            # Shipping terms\n",
    "            'cpt': 'cepat',\n",
    "            'cpet': 'cepat',\n",
    "            'kilat': 'cepat',\n",
    "            'lama': 'lambat',\n",
    "            'lelet': 'lambat',\n",
    "            \n",
    "            # Price terms\n",
    "            'murmer': 'murah',\n",
    "            'mumer': 'murah',\n",
    "            'worth': 'sebanding',\n",
    "            'worthit': 'sebanding',\n",
    "            'mahil': 'mahal',\n",
    "            \n",
    "            # Service terms\n",
    "            'rekom': 'rekomendasi',\n",
    "            'recommended': 'rekomendasi',\n",
    "            'respon': 'responsif',\n",
    "            'fast': 'cepat',\n",
    "            'slow': 'lambat',\n",
    "            \n",
    "            # General terms\n",
    "            'bgt': 'banget',\n",
    "            'bgt': 'banget',\n",
    "            'bener': 'benar',\n",
    "            'gak': 'tidak',\n",
    "            'ga': 'tidak',\n",
    "            'tp': 'tapi',\n",
    "            'jd': 'jadi',\n",
    "            'krn': 'karena',\n",
    "            'udh': 'sudah',\n",
    "            'udah': 'sudah',\n",
    "            'blm': 'belum',\n",
    "            'belom': 'belum'\n",
    "        }\n",
    "        \n",
    "        # Aspect keywords for multi-label classification\n",
    "        self.aspect_keywords = {\n",
    "            'kualitas_produk': {\n",
    "                'positive': ['bagus', 'berkualitas', 'original', 'asli', 'premium', 'excellent', 'kualitas', 'mantap'],\n",
    "                'negative': ['jelek', 'buruk', 'rusak', 'kw', 'palsu', 'fake', 'cacat', 'ancur', 'parah']\n",
    "            },\n",
    "            'harga': {\n",
    "                'positive': ['murah', 'worth', 'sebanding', 'value', 'affordable', 'terjangkau'],\n",
    "                'negative': ['mahal', 'overprice', 'kemahalan', 'expensive', 'pricey']\n",
    "            },\n",
    "            'pengiriman': {\n",
    "                'positive': ['cepat', 'kilat', 'express', 'fast', 'tepat', 'ontime'],\n",
    "                'negative': ['lama', 'lambat', 'telat', 'slow', 'delay', 'lelet']\n",
    "            },\n",
    "            'pelayanan': {\n",
    "                'positive': ['ramah', 'baik', 'responsif', 'helpful', 'fast', 'respon', 'sopan'],\n",
    "                'negative': ['buruk', 'jelek', 'tidak', 'slow', 'lambat', 'cuek', 'galak']\n",
    "            },\n",
    "            'performa': {\n",
    "                'positive': ['battery', 'speed', 'cepat', 'lancar', 'smooth', 'camera', 'bagus', 'performance'],\n",
    "                'negative': ['lemot', 'lag', 'hang', 'error', 'lambat', 'boros', 'panas', 'overheat']\n",
    "            },\n",
    "            'packaging': {\n",
    "                'positive': ['rapi', 'aman', 'bubble', 'wrap', 'packaging', 'bungkus', 'kemasan'],\n",
    "                'negative': ['rusak', 'jelek', 'buruk', 'hancur', 'penyok', 'lecek']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize Indonesian text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove numbers (but keep price-related ones)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Remove special characters but keep indonesian characters\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Normalize slang\n",
    "        words = text.split()\n",
    "        normalized_words = []\n",
    "        for word in words:\n",
    "            if word in self.slang_dict:\n",
    "                normalized_words.append(self.slang_dict[word])\n",
    "            else:\n",
    "                normalized_words.append(word)\n",
    "        \n",
    "        return ' '.join(normalized_words)\n",
    "    \n",
    "    def create_aspect_labels(self, df):\n",
    "        \"\"\"Create multi-label aspect classification labels\"\"\"\n",
    "        print(\"Creating aspect labels...\")\n",
    "        \n",
    "        for aspect, keywords in self.aspect_keywords.items():\n",
    "            # Initialize with zeros\n",
    "            df[f'has_{aspect}'] = 0\n",
    "            \n",
    "            # Check for aspect mentions\n",
    "            for _, row in df.iterrows():\n",
    "                text = row['clean_text'].lower()\n",
    "                \n",
    "                # Check if any keyword is present\n",
    "                has_positive = any(keyword in text for keyword in keywords['positive'])\n",
    "                has_negative = any(keyword in text for keyword in keywords['negative'])\n",
    "                \n",
    "                if has_positive or has_negative:\n",
    "                    df.at[row.name, f'has_{aspect}'] = 1\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_sentiment_labels(self, df):\n",
    "        \"\"\"Create sentiment labels for each aspect\"\"\"\n",
    "        print(\"Creating sentiment labels...\")\n",
    "        \n",
    "        for aspect, keywords in self.aspect_keywords.items():\n",
    "            # Initialize with neutral (0)\n",
    "            df[f'sentiment_{aspect}'] = 0\n",
    "            \n",
    "            for _, row in df.iterrows():\n",
    "                text = row['clean_text'].lower()\n",
    "                \n",
    "                # Count positive and negative keywords\n",
    "                positive_count = sum(1 for keyword in keywords['positive'] if keyword in text)\n",
    "                negative_count = sum(1 for keyword in keywords['negative'] if keyword in text)\n",
    "                \n",
    "                # Determine sentiment\n",
    "                if positive_count > negative_count:\n",
    "                    df.at[row.name, f'sentiment_{aspect}'] = 1  # Positive\n",
    "                elif negative_count > positive_count:\n",
    "                    df.at[row.name, f'sentiment_{aspect}'] = -1  # Negative\n",
    "                # else remains 0 (neutral)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, input_file='D:/projects/ecommerce-review-classifier/data/raw/tokopedia_reviews.csv', \n",
    "                    output_file='D:/projects/ecommerce-review-classifier/data/processed/processed_reviews1.csv'):\n",
    "        \"\"\"Main preprocessing pipeline\"\"\"\n",
    "        print(f\"Loading data from {input_file}\")\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        # All data\n",
    "        print(f\"Number of the data: {df.shape}\")\n",
    "\n",
    "        # --- HAPUS DATA YANG KOSONG DI 'ulasan' DAN 'nama_barang' ---\n",
    "        df.dropna(subset=['ulasan', 'nama_barang'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Rename to match expected column name\n",
    "        df.rename(columns={'ulasan': 'review_text'}, inplace=True)\n",
    "        \n",
    "        # Clean text\n",
    "        print(\"Cleaning text...\")\n",
    "        df['clean_text'] = df['review_text'].apply(self.clean_text)\n",
    "        \n",
    "        # Remove empty reviews (after cleaning)\n",
    "        df = df[df['clean_text'].str.strip().str.len() > 0]\n",
    "        \n",
    "        # Create aspect labels\n",
    "        df = self.create_aspect_labels(df)\n",
    "        \n",
    "        # Create sentiment labels\n",
    "        df = self.create_sentiment_labels(df)\n",
    "        \n",
    "        # Add text length feature\n",
    "        df['text_length'] = df['clean_text'].str.len()\n",
    "        \n",
    "        # Add word count feature\n",
    "        df['word_count'] = df['clean_text'].str.split().str.len()\n",
    "        \n",
    "        # Save processed data\n",
    "        #df.to_csv(output_file, index=False)\n",
    "        #print(f\"Processed data saved to {output_file}\")\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191997f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from D:/projects/ecommerce-review-classifier/data/raw/tokopedia_reviews.csv\n",
      "Number of the data: (19920, 4)\n",
      "Cleaning text...\n",
      "Creating aspect labels...\n",
      "Creating sentiment labels...\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ReviewPreprocessor()\n",
    "df = preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd03946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toko</th>\n",
       "      <th>nama_barang</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>has_kualitas_produk</th>\n",
       "      <th>has_harga</th>\n",
       "      <th>has_pengiriman</th>\n",
       "      <th>has_pelayanan</th>\n",
       "      <th>has_performa</th>\n",
       "      <th>has_packaging</th>\n",
       "      <th>sentiment_kualitas_produk</th>\n",
       "      <th>sentiment_harga</th>\n",
       "      <th>sentiment_pengiriman</th>\n",
       "      <th>sentiment_pelayanan</th>\n",
       "      <th>sentiment_performa</th>\n",
       "      <th>sentiment_packaging</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ismile-indonesia</td>\n",
       "      <td>Apple iPhone 13 128GB Garansi Resmi Indonesia</td>\n",
       "      <td>Barang original, berfungsi semua, gada kendala...</td>\n",
       "      <td>5</td>\n",
       "      <td>barang original berfungsi semua gada kendala p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ismile-indonesia</td>\n",
       "      <td>Vention Kabel Charger USB 2.0 Type C to Lightn...</td>\n",
       "      <td>Braided cable, kokoh, ada tutupnya, apalagi ?</td>\n",
       "      <td>5</td>\n",
       "      <td>braided cable kokoh ada tutupnya apalagi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ismile-indonesia</td>\n",
       "      <td>Apple iPhone 16 Garansi Resmi - 128GB 256GB 512GB</td>\n",
       "      <td>respon cepat, barang langsung dikirim. pembeli...</td>\n",
       "      <td>5</td>\n",
       "      <td>responsif cepat barang langsung dikirim pembel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ismile-indonesia</td>\n",
       "      <td>Apple iPhone 13 128GB Garansi Resmi Indonesia</td>\n",
       "      <td>puassss banget. barang sampai dengan selamat d...</td>\n",
       "      <td>5</td>\n",
       "      <td>puassss banget barang sampai dengan selamat da...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ismile-indonesia</td>\n",
       "      <td>Apple iPhone 16 Pro Max 128GB 256GB 512GB 1TB ...</td>\n",
       "      <td>Respon penjual baik\\nPengemasan aman\\nPengirim...</td>\n",
       "      <td>5</td>\n",
       "      <td>responsif penjual baik pengemasan aman pengiri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toko                                        nama_barang  \\\n",
       "0  ismile-indonesia      Apple iPhone 13 128GB Garansi Resmi Indonesia   \n",
       "1  ismile-indonesia  Vention Kabel Charger USB 2.0 Type C to Lightn...   \n",
       "2  ismile-indonesia  Apple iPhone 16 Garansi Resmi - 128GB 256GB 512GB   \n",
       "3  ismile-indonesia      Apple iPhone 13 128GB Garansi Resmi Indonesia   \n",
       "4  ismile-indonesia  Apple iPhone 16 Pro Max 128GB 256GB 512GB 1TB ...   \n",
       "\n",
       "                                         review_text  rating  \\\n",
       "0  Barang original, berfungsi semua, gada kendala...       5   \n",
       "1      Braided cable, kokoh, ada tutupnya, apalagi ?       5   \n",
       "2  respon cepat, barang langsung dikirim. pembeli...       5   \n",
       "3  puassss banget. barang sampai dengan selamat d...       5   \n",
       "4  Respon penjual baik\\nPengemasan aman\\nPengirim...       5   \n",
       "\n",
       "                                          clean_text  has_kualitas_produk  \\\n",
       "0  barang original berfungsi semua gada kendala p...                    1   \n",
       "1           braided cable kokoh ada tutupnya apalagi                    0   \n",
       "2  responsif cepat barang langsung dikirim pembel...                    0   \n",
       "3  puassss banget barang sampai dengan selamat da...                    1   \n",
       "4  responsif penjual baik pengemasan aman pengiri...                    0   \n",
       "\n",
       "   has_harga  has_pengiriman  has_pelayanan  has_performa  has_packaging  \\\n",
       "0          0               0              0             0              0   \n",
       "1          0               0              0             1              0   \n",
       "2          0               1              1             1              0   \n",
       "3          0               1              0             0              0   \n",
       "4          0               1              1             1              1   \n",
       "\n",
       "   sentiment_kualitas_produk  sentiment_harga  sentiment_pengiriman  \\\n",
       "0                          1                0                     0   \n",
       "1                          0                0                     0   \n",
       "2                          0                0                     1   \n",
       "3                          1                0                    -1   \n",
       "4                          0                0                     1   \n",
       "\n",
       "   sentiment_pelayanan  sentiment_performa  sentiment_packaging  text_length  \\\n",
       "0                    0                   0                    0           66   \n",
       "1                    0                  -1                    0           40   \n",
       "2                    1                   1                    0           55   \n",
       "3                    0                   0                    0           75   \n",
       "4                    1                   1                    1          158   \n",
       "\n",
       "   word_count  \n",
       "0           9  \n",
       "1           6  \n",
       "2           7  \n",
       "3          10  \n",
       "4          23  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf2b658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>has_kualitas_produk</th>\n",
       "      <th>has_harga</th>\n",
       "      <th>has_pengiriman</th>\n",
       "      <th>has_pelayanan</th>\n",
       "      <th>has_performa</th>\n",
       "      <th>has_packaging</th>\n",
       "      <th>sentiment_kualitas_produk</th>\n",
       "      <th>sentiment_harga</th>\n",
       "      <th>sentiment_pengiriman</th>\n",
       "      <th>sentiment_pelayanan</th>\n",
       "      <th>sentiment_performa</th>\n",
       "      <th>sentiment_packaging</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "      <td>16673.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.863012</td>\n",
       "      <td>0.478078</td>\n",
       "      <td>0.022072</td>\n",
       "      <td>0.245787</td>\n",
       "      <td>0.277694</td>\n",
       "      <td>0.520722</td>\n",
       "      <td>0.224675</td>\n",
       "      <td>0.446350</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.060877</td>\n",
       "      <td>0.071853</td>\n",
       "      <td>0.415882</td>\n",
       "      <td>0.205302</td>\n",
       "      <td>58.920230</td>\n",
       "      <td>9.277634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.602355</td>\n",
       "      <td>0.499534</td>\n",
       "      <td>0.146921</td>\n",
       "      <td>0.430566</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.499585</td>\n",
       "      <td>0.417380</td>\n",
       "      <td>0.521736</td>\n",
       "      <td>0.147236</td>\n",
       "      <td>0.482740</td>\n",
       "      <td>0.506432</td>\n",
       "      <td>0.566810</td>\n",
       "      <td>0.423648</td>\n",
       "      <td>45.686754</td>\n",
       "      <td>7.386894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating  has_kualitas_produk     has_harga  has_pengiriman  \\\n",
       "count  16673.000000         16673.000000  16673.000000    16673.000000   \n",
       "mean       4.863012             0.478078      0.022072        0.245787   \n",
       "std        0.602355             0.499534      0.146921        0.430566   \n",
       "min        1.000000             0.000000      0.000000        0.000000   \n",
       "25%        5.000000             0.000000      0.000000        0.000000   \n",
       "50%        5.000000             0.000000      0.000000        0.000000   \n",
       "75%        5.000000             1.000000      0.000000        0.000000   \n",
       "max        5.000000             1.000000      1.000000        1.000000   \n",
       "\n",
       "       has_pelayanan  has_performa  has_packaging  sentiment_kualitas_produk  \\\n",
       "count   16673.000000  16673.000000   16673.000000               16673.000000   \n",
       "mean        0.277694      0.520722       0.224675                   0.446350   \n",
       "std         0.447875      0.499585       0.417380                   0.521736   \n",
       "min         0.000000      0.000000       0.000000                  -1.000000   \n",
       "25%         0.000000      0.000000       0.000000                   0.000000   \n",
       "50%         0.000000      1.000000       0.000000                   0.000000   \n",
       "75%         1.000000      1.000000       0.000000                   1.000000   \n",
       "max         1.000000      1.000000       1.000000                   1.000000   \n",
       "\n",
       "       sentiment_harga  sentiment_pengiriman  sentiment_pelayanan  \\\n",
       "count     16673.000000          16673.000000         16673.000000   \n",
       "mean          0.018293              0.060877             0.071853   \n",
       "std           0.147236              0.482740             0.506432   \n",
       "min          -1.000000             -1.000000            -1.000000   \n",
       "25%           0.000000              0.000000             0.000000   \n",
       "50%           0.000000              0.000000             0.000000   \n",
       "75%           0.000000              0.000000             0.000000   \n",
       "max           1.000000              1.000000             1.000000   \n",
       "\n",
       "       sentiment_performa  sentiment_packaging   text_length    word_count  \n",
       "count        16673.000000         16673.000000  16673.000000  16673.000000  \n",
       "mean             0.415882             0.205302     58.920230      9.277634  \n",
       "std              0.566810             0.423648     45.686754      7.386894  \n",
       "min             -1.000000            -1.000000      1.000000      1.000000  \n",
       "25%              0.000000             0.000000     23.000000      4.000000  \n",
       "50%              0.000000             0.000000     48.000000      7.000000  \n",
       "75%              1.000000             0.000000     82.000000     13.000000  \n",
       "max              1.000000             1.000000    184.000000     40.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf130ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kualitas_produk: 7971 reviews (47.8%)\n",
      "harga: 368 reviews (2.2%)\n",
      "pengiriman: 4098 reviews (24.6%)\n",
      "pelayanan: 4630 reviews (27.8%)\n",
      "performa: 8682 reviews (52.1%)\n",
      "packaging: 3746 reviews (22.5%)\n"
     ]
    }
   ],
   "source": [
    "aspect_columns = [col for col in df.columns if col.startswith('has_')]\n",
    "for col in aspect_columns:\n",
    "    aspect_name = col.replace('has_', '')\n",
    "    count = df[col].sum()\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{aspect_name}: {count} reviews ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c056c8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution:\n",
      " rating\n",
      "1      283\n",
      "2       60\n",
      "3      161\n",
      "4      650\n",
      "5    15519\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Rating distribution:\\n\", df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea3727f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>has_kualitas_produk</th>\n",
       "      <th>has_harga</th>\n",
       "      <th>has_pengiriman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16836</th>\n",
       "      <td>terimakasih barng yg kupesan sudah datng</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16837</th>\n",
       "      <td>hp nya sehari pesan lgsung smpe dtng dlm k ada...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16838</th>\n",
       "      <td>bagus bang sesuai dengan kebutuhan</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16839</th>\n",
       "      <td>hssbzbzbxb</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16840</th>\n",
       "      <td>tzxrzdzff</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  rating  \\\n",
       "16836           terimakasih barng yg kupesan sudah datng       5   \n",
       "16837  hp nya sehari pesan lgsung smpe dtng dlm k ada...       5   \n",
       "16838                 bagus bang sesuai dengan kebutuhan       5   \n",
       "16839                                         hssbzbzbxb       4   \n",
       "16840                                          tzxrzdzff       4   \n",
       "\n",
       "       has_kualitas_produk  has_harga  has_pengiriman  \n",
       "16836                    0          0               0  \n",
       "16837                    0          0               0  \n",
       "16838                    1          0               0  \n",
       "16839                    0          0               0  \n",
       "16840                    0          0               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cols = ['clean_text', 'rating'] + aspect_columns[:3]\n",
    "df[sample_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43174ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df[[col for col in df.columns if col.startswith('has_')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c1d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.2\n",
    "val_size=0.1\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=42, stratify=y.iloc[:, 0]\n",
    ")\n",
    "val_size_adjusted = val_size / (1 - test_size)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=val_size_adjusted, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a970ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cbd73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed:\n",
      "Train: 11670 samples\n",
      "Validation: 1668 samples\n",
      "Test: 3335 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data split completed:\")\n",
    "print(f\"Train: {len(train_df)} samples\")\n",
    "print(f\"Validation: {len(val_df)} samples\")\n",
    "print(f\"Test: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6f8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training with Optuna Hyperparameter Tuning\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, jaccard_score, f1_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Suppress optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6f87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelModelTrainer:\n",
    "    def __init__(self, train_df, val_df, test_df):\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        # Prepare data\n",
    "        self.X_train = train_df['clean_text']\n",
    "        self.y_train = train_df[[col for col in train_df.columns if col.startswith('has_')]]\n",
    "        \n",
    "        self.X_val = val_df['clean_text']\n",
    "        self.y_val = val_df[[col for col in val_df.columns if col.startswith('has_')]]\n",
    "        \n",
    "        self.X_test = test_df['clean_text']\n",
    "        self.y_test = test_df[[col for col in test_df.columns if col.startswith('has_')]]\n",
    "        \n",
    "        # Results storage\n",
    "        self.results = {}\n",
    "    \n",
    "    def objective_rf(self, trial):\n",
    "        \"\"\"Objective function for Random Forest hyperparameter tuning\"\"\"\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "            ('classifier', MultiOutputClassifier(RandomForestClassifier(**params)))\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred = pipeline.predict(self.X_val)\n",
    "        \n",
    "        # Calculate accuracy (subset accuracy)\n",
    "        accuracy = accuracy_score(self.y_val, y_pred)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def objective_xgb(self, trial):\n",
    "        \"\"\"Objective function for XGBoost hyperparameter tuning\"\"\"\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "            ('classifier', MultiOutputClassifier(xgb.XGBClassifier(**params)))\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred = pipeline.predict(self.X_val)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(self.y_val, y_pred)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def objective_svm(self, trial):\n",
    "        \"\"\"Objective function for SVM hyperparameter tuning\"\"\"\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 0.1, 10.0),\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf']),\n",
    "            'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=3000, stop_words='english')),  # Reduced features for SVM\n",
    "            ('classifier', MultiOutputClassifier(SVC(**params)))\n",
    "        ])\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred = pipeline.predict(self.X_val)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(self.y_val, y_pred)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def train_random_forest(self, n_trials=20):\n",
    "        \"\"\"Train Random Forest with hyperparameter tuning\"\"\"\n",
    "        print(\"\\nTraining Random Forest with Optuna...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "        study.optimize(self.objective_rf, n_trials=n_trials)\n",
    "        \n",
    "        print(f\"Best RF parameters: {study.best_params}\")\n",
    "        print(f\"Best RF validation accuracy: {study.best_value:.4f}\")\n",
    "        \n",
    "        # Train final model with best parameters\n",
    "        best_params = study.best_params\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "            ('classifier', MultiOutputClassifier(RandomForestClassifier(**best_params)))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = pipeline.predict(self.X_test)\n",
    "        test_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        hamming = hamming_loss(self.y_test, y_pred)\n",
    "        jaccard = jaccard_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        self.results['Random Forest'] = {\n",
    "            'best_params': best_params,\n",
    "            'validation_accuracy': study.best_value,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'hamming_loss': hamming,\n",
    "            'jaccard_score': jaccard,\n",
    "            'f1_score': f1,\n",
    "            'training_time': training_time,\n",
    "            'model': pipeline\n",
    "        }\n",
    "        \n",
    "        print(f\"RF Training completed in {training_time:.2f} seconds\")\n",
    "        print(f\"RF Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def train_xgboost(self, n_trials=20):\n",
    "        \"\"\"Train XGBoost with hyperparameter tuning\"\"\"\n",
    "        print(\"\\nTraining XGBoost with Optuna...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "        study.optimize(self.objective_xgb, n_trials=n_trials)\n",
    "        \n",
    "        print(f\"Best XGB parameters: {study.best_params}\")\n",
    "        print(f\"Best XGB validation accuracy: {study.best_value:.4f}\")\n",
    "        \n",
    "        # Train final model with best parameters\n",
    "        best_params = study.best_params\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "            ('classifier', MultiOutputClassifier(xgb.XGBClassifier(**best_params)))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = pipeline.predict(self.X_test)\n",
    "        test_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        hamming = hamming_loss(self.y_test, y_pred)\n",
    "        jaccard = jaccard_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        self.results['XGBoost'] = {\n",
    "            'best_params': best_params,\n",
    "            'validation_accuracy': study.best_value,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'hamming_loss': hamming,\n",
    "            'jaccard_score': jaccard,\n",
    "            'f1_score': f1,\n",
    "            'training_time': training_time,\n",
    "            'model': pipeline\n",
    "        }\n",
    "        \n",
    "        print(f\"XGB Training completed in {training_time:.2f} seconds\")\n",
    "        print(f\"XGB Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def train_svm(self, n_trials=20):\n",
    "        \"\"\"Train SVM with hyperparameter tuning (reduced trials due to computational cost)\"\"\"\n",
    "        print(\"\\nTraining SVM with Optuna...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "        study.optimize(self.objective_svm, n_trials=n_trials)\n",
    "        \n",
    "        print(f\"Best SVM parameters: {study.best_params}\")\n",
    "        print(f\"Best SVM validation accuracy: {study.best_value:.4f}\")\n",
    "        \n",
    "        # Train final model with best parameters\n",
    "        best_params = study.best_params\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=3000, stop_words='english')),\n",
    "            ('classifier', MultiOutputClassifier(SVC(**best_params)))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = pipeline.predict(self.X_test)\n",
    "        test_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        hamming = hamming_loss(self.y_test, y_pred)\n",
    "        jaccard = jaccard_score(self.y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        self.results['SVM'] = {\n",
    "            'best_params': best_params,\n",
    "            'validation_accuracy': study.best_value,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'hamming_loss': hamming,\n",
    "            'jaccard_score': jaccard,\n",
    "            'f1_score': f1,\n",
    "            'training_time': training_time,\n",
    "            'model': pipeline\n",
    "        }\n",
    "        \n",
    "        print(f\"SVM Training completed in {training_time:.2f} seconds\")\n",
    "        print(f\"SVM Test Accuracy: {test_accuracy:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def train_all_models(self):\n",
    "        \"\"\"Train all models\"\"\"\n",
    "        print(\"\\nStarting Multi-Label Classification Training...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Train Random Forest\n",
    "        self.train_random_forest(n_trials=50)\n",
    "        \n",
    "        # Train XGBoost\n",
    "        self.train_xgboost(n_trials=50)\n",
    "        \n",
    "        # Train SVM (fewer trials due to computational cost)\n",
    "        self.train_svm(n_trials=30)\n",
    "        \n",
    "        print(\"\\nAll models training completed!\")\n",
    "        return self.results\n",
    "    \n",
    "    def display_results(self):\n",
    "        \"\"\"Display comparison of all models\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to display. Please train models first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"\\nMODEL COMPARISON RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_data = []\n",
    "        for model_name, metrics in self.results.items():\n",
    "            results_data.append({\n",
    "                'Model': model_name,\n",
    "                'Test Accuracy': f\"{metrics['test_accuracy']:.4f}\",\n",
    "                'Validation Accuracy': f\"{metrics['validation_accuracy']:.4f}\",\n",
    "                'Hamming Loss': f\"{metrics['hamming_loss']:.4f}\",\n",
    "                'Jaccard Score': f\"{metrics['jaccard_score']:.4f}\",\n",
    "                'F1 Score': f\"{metrics['f1_score']:.4f}\",\n",
    "                'Training Time (s)': f\"{metrics['training_time']:.2f}\"\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results_data)\n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        # Find best model\n",
    "        best_model = max(self.results.keys(), \n",
    "                        key=lambda x: self.results[x]['test_accuracy'])\n",
    "        \n",
    "        print(f\"\\n   BEST MODEL: {best_model}\")\n",
    "        print(f\"   Test Accuracy: {self.results[best_model]['test_accuracy']:.4f}\")\n",
    "        print(f\"   Training Time: {self.results[best_model]['training_time']:.2f}s\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e92e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Multi-Label Classification Training...\n",
      "============================================================\n",
      "\n",
      "Training Random Forest with Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-07-28 21:43:13,127] Trial 36 failed with parameters: {'n_estimators': 189, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\VICTUS\\AppData\\Local\\Temp\\ipykernel_6284\\3331212398.py\", line 39, in objective_rf\n",
      "    pipeline.fit(self.X_train, self.y_train)\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py\", line 450, in fit\n",
      "    super().fit(X, Y, sample_weight, **fit_params)\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py\", line 216, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py\", line 49, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 473, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-28 21:43:13,187] Trial 36 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultiLabelModelTrainer(train_df, val_df, test_df)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train all models\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m results_df \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mdisplay_results()\n",
      "Cell \u001b[1;32mIn[15], line 250\u001b[0m, in \u001b[0;36mMultiLabelModelTrainer.train_all_models\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Train Random Forest\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_random_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Train XGBoost\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_xgboost(n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 112\u001b[0m, in \u001b[0;36mMultiLabelModelTrainer.train_random_forest\u001b[1;34m(self, n_trials)\u001b[0m\n\u001b[0;32m    109\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    111\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[1;32m--> 112\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest RF parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest RF validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[15], line 39\u001b[0m, in \u001b[0;36mMultiLabelModelTrainer.objective_rf\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     33\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m     34\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     35\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, MultiOutputClassifier(RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)))\n\u001b[0;32m     36\u001b[0m ])\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[0;32m     42\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_val)\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py:216\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnderlying estimator does not support sample weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m fit_params_validated \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_validated\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\multioutput.py:49\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize and train models\n",
    "trainer = MultiLabelModelTrainer(train_df, val_df, test_df)\n",
    "\n",
    "# Train all models\n",
    "results = trainer.train_all_models()\n",
    "\n",
    "# Display results\n",
    "results_df = trainer.display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Make folder to save models\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# Model from result\n",
    "rf_model = trainer.results['Random Forest']['model']\n",
    "xgb_model = trainer.results['XGBoost']['model']\n",
    "svm_model = trainer.results['SVM']['model']\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, 'saved_models/random_forest_model.pkl')\n",
    "joblib.dump(xgb_model, 'saved_models/xgboost_model.pkl')\n",
    "joblib.dump(svm_model, 'saved_models/svm_model.pkl')\n",
    "\n",
    "print(\"\\nAll models saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41340eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
